{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[ANN]Taller2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5rfZ_hYaQ1Z",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"30%\" />\n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales I-2020 </h1>\n",
        "\n",
        "<H3 align='center'> Tarea 2 - Redes Neuronales Convolucionales y Recurrentes </H3>\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "**Temas**  \n",
        "\n",
        "* Entrenamiento de Redes Neuronales Profundas. \n",
        "* Modelos de Auto-Encoder\n",
        "* Redes Convolucionales y Recurrentes. \n",
        "\n",
        "**Formalidades**  \n",
        "* Equipos de trabajo de: 3 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
        "* Formato de entrega: envı́o de link Github y link de video Youtube o plataforma a convenir, todo esto vía Aula. \n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "### **Propuesta**\n",
        "* Se debe preparar una presentación de **15 a 20 minutos** donde se explique el cómo se va a realizar/resolver el taller, la metodología o propuesta de las componentes a experimentar y explorar. Más detalles en el Syllabus.\n",
        "* Fecha de encuentro Zoom: 12 de Junio en horario de clases.\n",
        "* Fecha de entrega de vídeo: Opcional para quienes presentaron y obligatorio para quienes no, a lo más 2 días después del encuentro.\n",
        "* Modalidad de Presentación (Zoom): En el primer bloque, se formarán 3 grupos para que alcancen a recibir feedback todos los equipos. En el segundo bloque, algunos equipos seleccionados presentarán a todo el curso. \n",
        "\n",
        "**Aún si la idea es aprender colaborativamente, valoraremos mucho la diversidad de ideas, por lo que las propuesta debiesen conservar su orientación inicial, excepto por el feedback que les entreguemos**\n",
        "\n",
        "### **Defensa**\n",
        "* Se debe preparar una presentación de **15 a 20 minutos** con los resultados obtenidos y conclusiones de la experiencia. \n",
        "* Se debe entregar el código, de preferencia en un (breve) Jupyter/IPython notebook, de modo que **permita reproducir los resultados** presentados. Si se entrega el código fuente se deben proveer instrucciones para su uso.\n",
        "* Fecha de encuentro Zoom: 26 de Junio, horario de clases.\n",
        "* Fecha de entrega de vídeo: 2 días antes de encuentro.\n",
        "* Fecha de entrega de Jypter (notebook): commits hasta 2 días antes del encuentro. \n",
        "* Modalidad de Presentación (Zoom): En ambos bloques algunos equipos seleccionados presentarán ante todo el curso, discusión y debate se generará en base a los resultados.\n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "La tarea se divide en secciones:\n",
        "\n",
        "[1.](#primero) Pregunta Libre   \n",
        "[2.](#segundo) Challenge Kaggle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTkbRyusPMok",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"primero\"></a>\n",
        "## 1. Pregunta Libre\n",
        "\n",
        "Refute o evidencie experimentalmente una de las siguientes afirmaciones \n",
        "\n",
        "\n",
        "> Tema 1. Un autoencoder simétrico (la arquitectura del encoder es espejo del encoder) es más efectivo para aprender una representación que un autoencoder asimétrico Esto vale tanto para arquitecturas densas como convolucionales. \n",
        "\n",
        "> Tema 2. Un denoising autoencoder (DAE) logra la misma robustez de representación que un autoencoder variacional (VAE).\n",
        "\n",
        "> Tema 3. Usando etiquetas, es posible mejorar significativamente la calidad de las representaciones aprendidas por un autoencoder, aún si se dispone de un pequeño porcentaje de datos con ellas. \n",
        "\n",
        "> Tema 4. Regularizar un autoencoder para obtener representaciones *sparse* (dispersas) permite mejorar la calidad de las representaciones obtenidas para datos que no están en el conjunto de entrenamiento. \n",
        "\n",
        "> Tema 5. Una arquitectura con encoder profundo y decoder no profundo (1 capa) es más efectiva que una con decoder profundo y encoder no profundo (1 capa). Esto vale tanto para arquitecturas densas como convolucionales. \n",
        "\n",
        "> Tema 6. En un VAE, modificar el regularizador, KL(q(z|x)|p(z)), para que sea simétrico, no tiene ningún efecto práctico sobre la representación aprendida.\n",
        "\n",
        "> Tema 7. Organizando adecuadamente las capas, *Dropout* es mucho más efectivo que *BatchNormalization* para regularizar redes convolucionales profundas y juntos no funcionan muy bien. \n",
        "\n",
        "> Tema 8.  Los optimizadores más populares en deep learning (*AdaGrad, RMSProp, Adam* y *Nadam*) funcionan mejor que un simple SGD porque evitan que la red caiga en óptimos locales con alto error de predicción. \n",
        "\n",
        "> Tema 9. *BatchNormalization* facilita el entrenamiento de una red porque reduce el covariate shift interno y estabiliza la magnitud de los gradientes.  \n",
        "\n",
        "> Tema 10. Una red *LSTM* ó *GRU* permite aprender dependencias de mucho más largo plazo y más eficientemente que una red recurrente tipo *Elman*.\n",
        "\n",
        "> Tema 11. En un problema en que hay dependencias temporales de largo plazo, una red recurrente *bidireccional* será siempre más efectiva que una red *uni-direccional*. \n",
        "\n",
        "> Tema 12. Una red recurrente es un modelo más efectivo para predicción de *series de tiempo* que un modelo auto-regresivo denso (feed-forward).\n",
        "\n",
        "> Tema 13. No tiene sentido usar una red convolucional para aprendizaje de secuencias, su error será siempre mayor que el de una red recurrente.\n",
        "\n",
        "> Tema 14. En predicción de series de tiempo con redes recurrentes, *Dropout* permite obtener intervalos de confianza para la predicción que cubren bien el valor real.\n",
        "\n",
        "> Tema 15. En un problema de apredizaje seq-2-seq, una red recurrente con mecanismos atencionales será siempre más efectiva que una arquitectura recurrente encoder-decoder sin atención.\n",
        "\n",
        "> Tema 16. Al resolver un problema de apredizaje seq-2-seq, una encoder recurrente no tiene ventajas sobre un encoder convolucional si se utilizan mecanismos atencionales en el decoder.\n",
        "\n",
        "**Reglas mínimas**: Validar en al menos 1 dataset sintético y 2 reales.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mro0DvciPO8t",
        "colab_type": "text"
      },
      "source": [
        "#### <a id=\"segundo\"></a>\n",
        "## 2.Challenge Kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no4BhCKje0PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}